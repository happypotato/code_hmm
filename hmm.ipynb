{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "class HMM(object): \n",
    "    # base class for different HMM models\n",
    "    def __init__(self, M, N):\n",
    "        # model is (A, B, pi) where A = Transition probs(states*states), B = Emission Probs(states*obs), pi = initial distribution(states)        # a model can be initialized to random parameters using a json file that has a random params model\n",
    "        # M:number of states of the model\n",
    "        # N:number of hidden states of the model\n",
    "        self.A = np.random.random((M, M)) \n",
    "        # Get transition probability\n",
    "        self.B = np.random.random((M, N)) \n",
    "        # Get emission probability\n",
    "        self.pi = np.random.random((1, M)) \n",
    "        # Get initial probability\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "    \n",
    "    def backward(self, obs):\n",
    "        # This function is for backward algorithm, suppose that A, B, pi are given, and it \n",
    "        #calculates a bwk matrix (obs*states).\n",
    "        # The backward algorithm can be used to calculate the likelihood of the probability\n",
    "        #P(Y_{k+1}, ... , Y_n|t_k=C)=sum_q P(Y_{k+2}, ... , Y_n|t_{k+1}=q)P(q|C)P(x_{k+1}|q)\n",
    "        #The backward probability b is the probability of seeing the observations from \n",
    "        #time t + 1 to the end, given that we are in state i at time t\n",
    "        self.bwk = [[0 for x in range(self.M)] for y in range(len(obs))] \n",
    "        #Initalize bwk to be empty matrix T*M\n",
    "        # Initialize base cases (t == T)\n",
    "        for y in range(self.M):\n",
    "            self.bwk[len(obs)-1][y] = 1 \n",
    "            #self.A[y][\"Final\"] #self.pi[y] * self.B[y][obs[0]]\n",
    "        for t in reversed(range(len(obs)-1)):\n",
    "            for y in range(self.M):\n",
    "                self.bwk[t][y] = sum((self.bwk[t+1][y1] * self.A[y][y1] * self.B[y1][obs[t+1]]) for y1 in range(self.M))#beta_k(C)=\\sum_q beta_{k+1}(q)P(q|C)P(w_{k+1}|q)\n",
    "        prob = sum((self.pi[0][y]* self.B[y][obs[0]] * self.bwk[0][y]) for y in range(self.M))\n",
    "\n",
    "        return prob \n",
    "        #This prob is the likelihood of the input obs   \n",
    "    \n",
    "    def forward(self, obs):\n",
    "        # This function is for forward algorithm, suppose that A, B, pi are given, and it calculates a fwd matrix (obs*states).\n",
    "        # The forward algorithm can be used to calculate the likelihood of the model\n",
    "        #P(Y1, ... , Yn)=sum_t(\\prod_i P(Y[i]|t[i])P(t[i]|t[i-1])\n",
    "        self.fwd = [[0 for x in range(self.M)] for y in range(len(obs))]  \n",
    "        #Initalize fwk to be empty matrix, and finally fwd is N*T\n",
    "        # Initialize base cases (t == 0)\n",
    "        for y in range(self.M):\n",
    "            self.fwd[0][y] = self.pi[0][y] * self.B[y][obs[0]] \n",
    "            #alpha_1(q)=p(w1,t1=q)=P(t1=q|t0)*p(w1|t1=q)\n",
    "        # Run Forward algorithm for t > 0\n",
    "        for t in range(1, len(obs)):\n",
    "            #self.fwd.append({})\n",
    "            for y in range(self.M):\n",
    "                self.fwd[t][y] = sum((self.fwd[t-1][y0] * self.A[y0][y] * self.B[y][obs[t]]) for y0 in range(self.M))\n",
    "                #alpha_k(q)=\\sum_q1 alpha_{k-1}(q1)P(t_k=q|t_{k-1}=q1)P(w_k|t+k=q)\n",
    "        prob = sum((self.fwd[len(obs) - 1][s]) for s in range(self.M))\n",
    "        # The likelihood of input equals to the summation of fwd[N][t]\n",
    "        return prob\n",
    "\n",
    "    def viterbi(self, obs):\n",
    "    #the task of determining which sequence of variables is the underlying source of some sequence of observations is called the decoding task\n",
    "    #Decoding: Given as input an HMM = (A, B, pi) and a sequence of observations O = Y_1, ... Y_N, find the most probable sequence of states Q = X_1, ... X_T.\n",
    "    # Goal: find the best path!\n",
    "    # argmax_t P(Y1, ... Y_N, X_1, ..., X_T|A, B, pi)\n",
    "        vit = [[0 for x in range(self.M)] for y in range(len(obs))] # matrix\n",
    "        path = {} # path\n",
    "        # Initialize base cases (t == 0)\n",
    "        for y in range(self.M):\n",
    "            vit[0][y] = self.pi[0][y] * self.B[y][obs[0]]\n",
    "            path[y] = [y]\n",
    "        \n",
    "        # Run Viterbi for t > 0\n",
    "        for t in range(1, len(obs)):\n",
    "            #vit.append({})\n",
    "            newpath = {}\n",
    "            for y in range(self.M):\n",
    "                (prob, state) = max((vit[t-1][y0] * self.A[y0][y] * self.B[y][obs[t]], y0) for y0 in range(self.M))\n",
    "                vit[t][y] = prob\n",
    "                newpath[y] = path[state] + [y]\n",
    "            # Don't need to remember the old paths\n",
    "            path = newpath\n",
    "        n = 0           \n",
    "        # if only one element is observed max is sought in the initialization values\n",
    "        if len(obs)!=1:\n",
    "            n = t\n",
    "        (prob, state) = max((vit[n][y], y) for y in range(self.M))\n",
    "        return (prob, path[state])\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward_backward(self, obs): \n",
    "        # returns model given the initial model and observations\n",
    "        #forward-backward algorithm is a special case of EM algorithm\n",
    "        #The Baum-Welch algorithm iteratively estimate the counts. \n",
    "        #We will start with an estimate for the transition and observation probabilities and \n",
    "        #then use these estimated probabilities to derive better and better probabilities. \n",
    "        #We get our estimated probabilities by computing the forward probability for an observation \n",
    "        #and then dividing that probability mass among all the different paths that contributed to this forward probability.\n",
    "        gamma = [[0 for x in range(self.M)] for y in range(len(obs))]\n",
    "        # this is needed to keep track of finding a state i at a time t for all i and all t\n",
    "        zi = [[[0 for x in range(self.M)] for y in range(self.M)] for z in range(len(obs))]  \n",
    "        # this is needed to keep track of finding a state i at a time t and j at a time (t+1) for all i and all j and all t\n",
    "        # get alpha and beta tables computes\n",
    "        p_obs = self.forward(obs)\n",
    "        self.backward(obs)\n",
    "        # compute gamma values\n",
    "        for t in range(len(obs)):\n",
    "            for y in range(self.M):\n",
    "                gamma[t][y] = (self.fwd[t][y] * self.bwk[t][y]) / p_obs\n",
    "                if t == 0:\n",
    "                    self.pi[0][y] = gamma[t][y]\n",
    "                #gamma[t][y]=P(q_t=j|Y_1, ..., Y_N,A,B,pi)=P(q_t=j,Y_1, ..., Y_N|A,B,pi)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "                #=alpha_t(j)beta_t(j)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "                #compute zi values up to T - 1\n",
    "                if t == len(obs) - 1:\n",
    "                    continue\n",
    "                #zi[t][y] = {}\n",
    "                for y1 in range(self.M):\n",
    "                    zi[t][y][y1] = self.fwd[t][y] * self.A[y][y1] * self.B[y1][obs[t + 1]] * self.bwk[t + 1][y1] / p_obs\n",
    "        #z[t][i][j]=P(q_t=i,q_{t+1}=j|Y_1, ..., Y_N,A,B,pi)\n",
    "        #=P(q_t=i,q_{t+1}=j,Y_1, ..., Y_N|A,B,pi)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "        #=alpha_t(i)a_{ij}b_j(O_{t+1})beta_{t+1}(j)/apha_t(X_T)\n",
    "        return (gamma,zi)\n",
    "    \n",
    "    \n",
    "    def baum_welch(self,obs):\n",
    "        gamma = [[0 for x in range(self.M)] for y in range(len(obs))]\n",
    "        # this is needed to keep track of finding a state i at a time t for all i and all t\n",
    "        zi = [[[0 for x in range(self.M)] for y in range(self.M)] for z in range(len(obs))]  \n",
    "        # this is needed to keep track of finding a state i at a time t and j at a time (t+1) for all i and all j and all t\n",
    "\n",
    "\n",
    "        # now that we have gamma and zi let us re-estimate\n",
    "        (gamma,zi)=self.forward_backward(obs)\n",
    "        for y in range(self.M):\n",
    "            for y1 in range(self.M):\n",
    "                # we will now compute new a_ij\n",
    "                #a_{ij)=expected number of transitions from state i to state j/expected number of transitions from state i\n",
    "                val = sum([zi[t][y][y1] for t in range(len(obs) - 1)]) #\n",
    "                val /= sum([gamma[t][y] for t in range(len(obs) - 1)])\n",
    "                self.A[y][y1] = val\n",
    "        # re estimate gamma\n",
    "        for y in range(self.M):\n",
    "            for k in range(self.N): \n",
    "                # for all symbols vk\n",
    "                val = 0.0\n",
    "                for t in range(len(obs)):\n",
    "                    if obs[t] == k :\n",
    "                        val += gamma[t][y]\n",
    "                val /= sum([gamma[t][y] for t in range(len(obs))])\n",
    "                self.B[y][k] = val\n",
    "                    #b_j(v_k)=expected number of times in state j and observing symbol vk/expected number of times in state j\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations =  [1, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "hmm=HMM(3,4)\n",
    "observations=[1, 2, 1]\n",
    "print \"Observations = \", observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fwd Prob =  0.280608235864\n"
     ]
    }
   ],
   "source": [
    "p1=hmm.backward(observations)\n",
    "print \" Fwd Prob = \", p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fwd Prob =  0.280608235864\n"
     ]
    }
   ],
   "source": [
    "p2=hmm.forward(observations)\n",
    "print \" Fwd Prob = \", p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Probability =  0.130987542378  Hidden State Sequence =  [1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "prob, hidden_states = hmm.viterbi(observations)\n",
    "print \"Max Probability = \", prob, \" Hidden State Sequence = \", hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zi=  [[[0.052975165185933246, 0.17450369898850387, 0.067538265421146937], [0.054772558080126238, 0.54823984380346746, 0.088256567948670345], [0.0050167120794486278, 0.0083770430029874252, 0.00032014548971584533]], [[0.021279356416313872, 0.079494630637479441, 0.011990448291714787], [0.05596579703509013, 0.63529765608062649, 0.039857132679242228], [0.053428586771127842, 0.10117943374653986, 0.0015069583418654518]], [[0, 0, 0], [0, 0, 0], [0, 0, 0]]]\n",
      "gamma= [[0.29501712959558407, 0.69126896983226405, 0.013713900572151898], [0.11276443534550812, 0.73112058579495887, 0.15611497885953315], [0.13067374022253184, 0.81597172046464572, 0.053354539312822462]]\n"
     ]
    }
   ],
   "source": [
    "(gamma,zi)=hmm.forward_backward(observations)\n",
    "print \"zi= \", zi\n",
    "print \"gamma=\", gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new model parameters after 1 iteration are: \n",
      "A =  [[ 0.18193695  0.62093051  0.19713254]\n",
      " [ 0.0778423   0.83239989  0.0897578 ]\n",
      " [ 0.34265928  0.64744357  0.00989715]]\n",
      "B =  [[ 0.          0.80112494  0.19887506  0.        ]\n",
      " [ 0.          0.67206687  0.32793313  0.        ]\n",
      " [ 0.          0.25969488  0.74030512  0.        ]]\n",
      "pi =  [[ 0.32044948  0.67664734  0.00290318]]\n"
     ]
    }
   ],
   "source": [
    "hmm.baum_welch(observations)\n",
    "print \"The new model parameters after 1 iteration are: \"\n",
    "print \"A = \", hmm.A\n",
    "print \"B = \", hmm.B\n",
    "print \"pi = \", hmm.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
