{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "class HMM(object): \n",
    "    # base class for different HMM models\n",
    "    def __init__(self, T, O, pi):\n",
    "        # model is (T, O, pi) where T = Transition probs(hidden_states*hidden_states), \n",
    "        # O = Emission Probs(hidden_states*states), pi = initial distribution(hidden_states)               \n",
    "        if T is None:\n",
    "            print \"Error: You should provide the transition matrix\"\n",
    "            sys.exit() # Read in parameters from the file of model_name\n",
    "        if O is None:\n",
    "            print \"Error: You should provide the emission matrix\"\n",
    "            sys.exit() # Read in parameters from the file of model_name\n",
    "        if pi is None:\n",
    "            print \"Error: You should provide the initial probability\"\n",
    "            sys.exit() # Read in parameters from the file of model_name           \n",
    "        self.pi=pi\n",
    "        self.T=T\n",
    "        self.O=O\n",
    "        self.M=T.shape[1]  # M:number of hidden states of the model\n",
    "        self.N=O.shape[1]  # N:number of states of the model\n",
    "\n",
    "        \n",
    "    def backward(self, obs):\n",
    "        # This function is for backward algorithm, suppose that T, O, pi \n",
    "        #are given, and it calculates a bwk matrix (obs*states).\n",
    "        # The backward algorithm can be used to calculate the likelihood \n",
    "        #of the probability P(Y_{k+1}, ... , Y_n|t_k=C)\n",
    "        #=sum_q P(Y_{k+2}, ... , Y_n|t_{k+1}=q)P(q|C)P(x_{k+1}|q)\n",
    "        #The backward probability b is the probability of seeing the observations from \n",
    "        #time t + 1 to the end, given that we are in state i at time t\n",
    "        self.bwk = [[0 for x in range(self.M)] for y in range(len(obs))] \n",
    "        # Initalize bwk to be empty matrix T*M\n",
    "        # Initialize base cases (t == T)\n",
    "        for y in range(self.M):\n",
    "            self.bwk[len(obs)-1][y] = 1 \n",
    "        for t in reversed(range(len(obs)-1)):\n",
    "            for y in range(self.M):\n",
    "                self.bwk[t][y] = sum((self.bwk[t+1][y1] * self.T[y][y1] * self.O[y1][obs[t+1]]) \n",
    "                                    for y1 in range(self.M))\n",
    "                #beta_k(C)=\\sum_q beta_{k+1}(q)P(q|C)P(w_{k+1}|q)\n",
    "        prob = sum((self.pi[0][y]* self.O[y][obs[0]] * self.bwk[0][y]) for y in range(self.M))\n",
    "\n",
    "        return prob \n",
    "        #This prob is the likelihood of the input obs   \n",
    " \n",
    "\n",
    "    def forward(self, obs):\n",
    "        # This function is for forward algorithm, suppose that A, B, pi are given, \n",
    "        #and it calculates a fwd matrix (obs*states).\n",
    "        # The forward algorithm can be used to calculate the likelihood of the model\n",
    "        #P(Y1, ... , Yn)=sum_t(\\prod_i P(Y[i]|t[i])P(t[i]|t[i-1])\n",
    "        self.fwd = [[0 for x in range(self.M)] for y in range(len(obs))]  \n",
    "        #Initalize fwk to be empty matrix, and finally fwd is T*M\n",
    "        # Initialize base cases (t == 0)\n",
    "        for y in range(self.M):\n",
    "            self.fwd[0][y] = self.pi[0][y] * self.O[y][obs[0]] \n",
    "            #alpha_1(q)=p(w1,t1=q)=P(t1=q|t0)*p(w1|t1=q)\n",
    "        # Run Forward algorithm for t > 0\n",
    "        for t in range(1, len(obs)):\n",
    "            for y in range(self.M):\n",
    "                self.fwd[t][y] = sum((self.fwd[t-1][y0] * self.T[y0][y] * self.O[y][obs[t]]) \n",
    "                                     for y0 in range(self.M))\n",
    "                #alpha_k(q)=\\sum_q1 alpha_{k-1}(q1)P(t_k=q|t_{k-1}=q1)P(w_k|t+k=q)\n",
    "        prob = sum((self.fwd[len(obs) - 1][s]) for s in range(self.M))\n",
    "        # The likelihood of input equals to the summation of fwd[N][t]\n",
    "        return prob\n",
    "\n",
    "    \n",
    "    def viterbi(self, obs):\n",
    "    #the task of determining which sequence of variables is the underlying source \n",
    "    #of some sequence of observations is called the decoding task\n",
    "    #Decoding: Given as input an HMM = (A, B, pi) and a sequence of observations \n",
    "    #O = Y_1, ... Y_N, find the most probable sequence of states Q = X_1, ... X_T.\n",
    "    # Goal: find the best path!\n",
    "    # argmax_t P(Y1, ... Y_N, X_1, ..., X_T|A, B, pi)\n",
    "        vit = [[0 for x in range(self.M)] for y in range(len(obs))] \n",
    "        # matrix\n",
    "        path = {} \n",
    "        # path\n",
    "        # Initialize base cases (t == 0)\n",
    "        for y in range(self.M):\n",
    "            vit[0][y] = self.pi[0][y] * self.O[y][obs[0]]\n",
    "            path[y] = [y]\n",
    "        \n",
    "        # Run Viterbi for t > 0\n",
    "        for t in range(1, len(obs)):\n",
    "            newpath = {}\n",
    "            for y in range(self.M):\n",
    "                (prob, state) = max((vit[t-1][y0] * self.T[y0][y] * self.O[y][obs[t]], y0) \n",
    "                                    for y0 in range(self.M))\n",
    "                vit[t][y] = prob\n",
    "                newpath[y] = path[state] + [y]\n",
    "            # Don't need to remember the old paths\n",
    "            path = newpath\n",
    "        n = 0           \n",
    "        # if only one element is observed max is sought in the initialization values\n",
    "        if len(obs)!=1:\n",
    "            n = t\n",
    "        (prob, state) = max((vit[n][y], y) for y in range(self.M))\n",
    "        return (prob, path[state])\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward_backward(self, obs): \n",
    "        #Output matrix gamma: gamma[t][y]=P(q_t=j|Y_1, ..., Y_N,A,B,pi)\n",
    "        #and tensor zi: zi[t][i][j]=P(q_t=i,q_{t+1}=j|Y_1, ..., Y_N,A,B,pi)\n",
    "        gamma = [[0 for x in range(self.M)] for y in range(len(obs))]\n",
    "        # this is needed to keep track of finding a state i at a time t for all i and all t\n",
    "        zi = [[[0 for x in range(self.M)] for y in range(self.M)] for z in range(len(obs))]  \n",
    "        # this is needed to keep track of finding a state i at a time t and j at a time (t+1) \n",
    "        #for all i and all j and all t\n",
    "        # get alpha and beta tables computes\n",
    "        p_obs = self.forward(obs)\n",
    "        self.backward(obs)\n",
    "        # compute gamma values\n",
    "        for t in range(len(obs)):\n",
    "            for y in range(self.M):\n",
    "                gamma[t][y] = (self.fwd[t][y] * self.bwk[t][y]) / p_obs\n",
    "                if t == 0:\n",
    "                    self.pi[0][y] = gamma[t][y]\n",
    "                #gamma[t][y]=P(q_t=j|Y_1, ..., Y_N,A,B,pi)\n",
    "                #=P(q_t=j,Y_1, ..., Y_N|A,B,pi)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "                #=alpha_t(j)beta_t(j)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "                #compute zi values up to T - 1\n",
    "                if t == len(obs) - 1:\n",
    "                    continue\n",
    "                for y1 in range(self.M):\n",
    "                    zi[t][y][y1] = self.fwd[t][y] * self.T[y][y1] * self.O[y1][obs[t + 1]] * self.bwk[t + 1][y1] / p_obs\n",
    "        #zi[t][i][j]=P(q_t=i,q_{t+1}=j|Y_1, ..., Y_N,A,B,pi)\n",
    "        #=P(q_t=i,q_{t+1}=j,Y_1, ..., Y_N|A,B,pi)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "        #=alpha_t(i)a_{ij}b_j(O_{t+1})beta_{t+1}(j)/apha_t(X_T)\n",
    "        return (gamma,zi)\n",
    "    \n",
    "    \n",
    "    def baum_welch(self,obs):\n",
    "        # returns model given the initial model and observations  \n",
    "        #The Baum-Welch algorithm iteratively estimate the counts.\n",
    "        #We will start with an estimate for the transition and observation probabilities and \n",
    "        #then use these estimated probabilities to derive better and better probabilities. \n",
    "        #We get our estimated probabilities by computing the forward probability for \n",
    "        #an observation and then dividing that probability mass among all the different \n",
    "        #paths that contributed to this forward probability.\n",
    "        gamma = [[0 for x in range(self.M)] for y in range(len(obs))]\n",
    "        zi = [[[0 for x in range(self.M)] for y in range(self.M)] for z in range(len(obs))]  \n",
    "\n",
    "        # now that we have gamma and zi let us re-estimate\n",
    "        (gamma,zi)=self.forward_backward(obs)\n",
    "        for y in range(self.M):\n",
    "            for y1 in range(self.M):\n",
    "                # we will now compute new a_ij\n",
    "                #a_{ij)=expected number of transitions from state i to state j/expected number \n",
    "                #of transitions from state i\n",
    "                val = sum([zi[t][y][y1] for t in range(len(obs) - 1)]) #\n",
    "                val /= sum([gamma[t][y] for t in range(len(obs) - 1)])\n",
    "                self.T[y][y1] = val\n",
    "        # re estimate gamma\n",
    "        for y in range(self.M):\n",
    "            for k in range(self.N): \n",
    "                # for all symbols vk\n",
    "                val = 0.0\n",
    "                for t in range(len(obs)):\n",
    "                    if obs[t] == k :\n",
    "                        val += gamma[t][y]\n",
    "                val /= sum([gamma[t][y] for t in range(len(obs))])\n",
    "                self.O[y][k] = val\n",
    "                    #b_j(v_k)=expected number of times in state j and observing symbol vk/expected \n",
    "                    #number of times in state j\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M=randint(0,10)\n",
    "N=randint(0,10)   \n",
    "T_raw = np.random.random((M, M)) \n",
    "row_sums_T= T_raw.sum(axis=1)\n",
    "T = T_raw / row_sums_T[:, np.newaxis]\n",
    "# Get transition probability\n",
    "O_raw = np.random.random((M, N))\n",
    "row_sums_O = O_raw.sum(axis=1)\n",
    "O = O_raw / row_sums_O[:, np.newaxis]\n",
    "# Get emission probability\n",
    "pi_raw = np.random.random((1, M)) \n",
    "row_sums_pi = pi_raw.sum(axis=1)\n",
    "pi = pi_raw / row_sums_pi[:, np.newaxis]\n",
    "# Get initial probability\n",
    "hmm=HMM(T,O,pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M= 4 N= 6 Observations =  [0, 3, 0, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "#M=randint(0,10)\n",
    "#N=randint(0,10)\n",
    "#hmm=HMM(M,N)\n",
    "T=randint(0,10)\n",
    "observations = []\n",
    "for i in xrange(0,T):\n",
    "    observations.append(randint(0,N-1))\n",
    "#observations=[1,0,1,1]\n",
    "print \"M=\", M, \"N=\", N, \"Observations = \", observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fwd Prob =  1.86500487578e-05\n"
     ]
    }
   ],
   "source": [
    "p1=hmm.backward(observations)\n",
    "print \" Fwd Prob = \", p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fwd Prob =  1.86500487578e-05\n"
     ]
    }
   ],
   "source": [
    "p2=hmm.forward(observations)\n",
    "print \" Fwd Prob = \", p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Probability =  8.17710112583e-07  Hidden State Sequence =  [1, 1, 3, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "prob, hidden_states = hmm.viterbi(observations)\n",
    "print \"Max Probability = \", prob, \" Hidden State Sequence = \", hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zi=  [[[0.044838056867513951, 0.12883847772164803, 0.060823296206747909, 0.011634157372551288], [0.029216654017497606, 0.21166974870675034, 0.035820915889268209, 0.089876163092098602], [0.021445583296885087, 0.027772648827908152, 0.010726608318446906, 0.019894096675005954], [0.062249072962921231, 0.19148879278696393, 0.044618456459364818, 0.0090872707984281237]], [[0.072174774960443278, 0.042291660932070672, 0.012396794218248033, 0.030886137034055856], [0.072639800037657354, 0.10731821940637207, 0.011276689778834675, 0.36853495882040627], [0.053192055098292682, 0.014047424652775403, 0.0033687758442698481, 0.081381021278489923], [0.066617186628291539, 0.041789508431245917, 0.0060460081264494406, 0.016038984752097057]], [[0.067766358665628385, 0.12830717610185419, 0.050633500614105195, 0.017916781343097064], [0.021437189365271909, 0.10233734748784644, 0.014476870438829698, 0.067195406130515972], [0.010763641872560658, 0.009184947420339722, 0.0029654078591246158, 0.010174270815777006], [0.13915050016976238, 0.28205463452461682, 0.054937268309471848, 0.020698698881198161]], [[0.053829130984195353, 0.12210916785522766, 0.050696213553412237, 0.012483177680388067], [0.050569563172226627, 0.28923418418087876, 0.043045761641578535, 0.13903459653997322], [0.038456717489650093, 0.03931730605404915, 0.013354626848247984, 0.031884396829584119], [0.02859143877298477, 0.069435023225742576, 0.014228288104701968, 0.0037304070671588846]], [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]]\n",
      "gamma= [[0.24613398816846119, 0.36658348170561478, 0.079838937118246092, 0.30744359300767804], [0.15774936714481788, 0.55976966804327033, 0.15198927687382785, 0.13049168793808394], [0.26462381672468482, 0.20544681342246404, 0.033088267967801996, 0.4968411018850491], [0.23911769007322334, 0.52188410553465714, 0.12301304722153136, 0.11598515717058817], [0.17144685041905686, 0.52009568131589823, 0.12132489014794073, 0.18713257811710426]]\n"
     ]
    }
   ],
   "source": [
    "(gamma,zi)=hmm.forward_backward(observations)\n",
    "print \"zi= \", zi\n",
    "print \"gamma=\", gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new model parameters after 1 iteration are: \n",
      "T =  [[ 0.25161359  0.47203239  0.20020012  0.0761539 ]\n",
      " [ 0.1080173   0.4121652   0.05928515  0.42053234]\n",
      " [ 0.33175851  0.19885502  0.0628415   0.40654497]\n",
      " [ 0.26864787  0.5699989   0.11837006  0.04298316]]\n",
      "O =  [[ 0.5404046   0.          0.          0.4595954   0.          0.        ]\n",
      " [ 0.20002386  0.          0.          0.79997614  0.          0.        ]\n",
      " [ 0.09358128  0.          0.          0.90641872  0.          0.        ]\n",
      " [ 0.69345462  0.          0.          0.30654538  0.          0.        ]]\n",
      "pi =  [[ 0.42682853  0.20521318  0.01106486  0.35689343]]\n"
     ]
    }
   ],
   "source": [
    "hmm.baum_welch(observations)\n",
    "print \"The new model parameters after 1 iteration are: \"\n",
    "print \"T = \", hmm.T\n",
    "print \"O = \", hmm.O\n",
    "print \"pi = \", hmm.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
