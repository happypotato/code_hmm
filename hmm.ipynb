{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "class HMM(object): \n",
    "    # base class for different HMM models\n",
    "    def __init__(self, M, N):\n",
    "        # model is (A, B, pi) where A = Transition probs(hidden_states*hidden_states), \n",
    "        #B = Emission Probs(hidden_states*states), pi = initial distribution(hidden_states)        \n",
    "        # M:number of hidden states of the model\n",
    "        # N:number of states of the model\n",
    "        self.A_raw = np.random.random((M, M)) \n",
    "        self.row_sums_A = self.A_raw.sum(axis=1)\n",
    "        self.A = self.A_raw / self.row_sums_A[:, np.newaxis]\n",
    "        # Get transition probability\n",
    "        self.B_raw = np.random.random((M, N))\n",
    "        self.row_sums_B = self.B_raw.sum(axis=1)\n",
    "        self.B = self.B_raw / self.row_sums_B[:, np.newaxis]\n",
    "        # Get emission probability\n",
    "        self.pi_raw = np.random.random((1, M)) \n",
    "        self.row_sums_pi = self.pi_raw.sum(axis=1)\n",
    "        self.pi = self.pi_raw / self.row_sums_pi[:, np.newaxis]\n",
    "        # Get initial probability\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "\n",
    "        \n",
    "    def backward(self, obs):\n",
    "        # This function is for backward algorithm, suppose that A, B, pi \n",
    "        #are given, and it calculates a bwk matrix (obs*states).\n",
    "        # The backward algorithm can be used to calculate the likelihood \n",
    "        #of the probability P(Y_{k+1}, ... , Y_n|t_k=C)\n",
    "        #=sum_q P(Y_{k+2}, ... , Y_n|t_{k+1}=q)P(q|C)P(x_{k+1}|q)\n",
    "        #The backward probability b is the probability of seeing the observations from \n",
    "        #time t + 1 to the end, given that we are in state i at time t\n",
    "        self.bwk = [[0 for x in range(self.M)] for y in range(len(obs))] \n",
    "        # Initalize bwk to be empty matrix T*M\n",
    "        # Initialize base cases (t == T)\n",
    "        for y in range(self.M):\n",
    "            self.bwk[len(obs)-1][y] = 1 \n",
    "        for t in reversed(range(len(obs)-1)):\n",
    "            for y in range(self.M):\n",
    "                self.bwk[t][y] = sum((self.bwk[t+1][y1] * self.A[y][y1] * self.B[y1][obs[t+1]]) \n",
    "                                    for y1 in range(self.M))\n",
    "                #beta_k(C)=\\sum_q beta_{k+1}(q)P(q|C)P(w_{k+1}|q)\n",
    "        prob = sum((self.pi[0][y]* self.B[y][obs[0]] * self.bwk[0][y]) for y in range(self.M))\n",
    "\n",
    "        return prob \n",
    "        #This prob is the likelihood of the input obs   \n",
    " \n",
    "\n",
    "    def forward(self, obs):\n",
    "        # This function is for forward algorithm, suppose that A, B, pi are given, \n",
    "        #and it calculates a fwd matrix (obs*states).\n",
    "        # The forward algorithm can be used to calculate the likelihood of the model\n",
    "        #P(Y1, ... , Yn)=sum_t(\\prod_i P(Y[i]|t[i])P(t[i]|t[i-1])\n",
    "        self.fwd = [[0 for x in range(self.M)] for y in range(len(obs))]  \n",
    "        #Initalize fwk to be empty matrix, and finally fwd is T*M\n",
    "        # Initialize base cases (t == 0)\n",
    "        for y in range(self.M):\n",
    "            self.fwd[0][y] = self.pi[0][y] * self.B[y][obs[0]] \n",
    "            #alpha_1(q)=p(w1,t1=q)=P(t1=q|t0)*p(w1|t1=q)\n",
    "        # Run Forward algorithm for t > 0\n",
    "        for t in range(1, len(obs)):\n",
    "            for y in range(self.M):\n",
    "                self.fwd[t][y] = sum((self.fwd[t-1][y0] * self.A[y0][y] * self.B[y][obs[t]]) \n",
    "                                     for y0 in range(self.M))\n",
    "                #alpha_k(q)=\\sum_q1 alpha_{k-1}(q1)P(t_k=q|t_{k-1}=q1)P(w_k|t+k=q)\n",
    "        prob = sum((self.fwd[len(obs) - 1][s]) for s in range(self.M))\n",
    "        # The likelihood of input equals to the summation of fwd[N][t]\n",
    "        return prob\n",
    "\n",
    "    \n",
    "    def viterbi(self, obs):\n",
    "    #the task of determining which sequence of variables is the underlying source \n",
    "    #of some sequence of observations is called the decoding task\n",
    "    #Decoding: Given as input an HMM = (A, B, pi) and a sequence of observations \n",
    "    #O = Y_1, ... Y_N, find the most probable sequence of states Q = X_1, ... X_T.\n",
    "    # Goal: find the best path!\n",
    "    # argmax_t P(Y1, ... Y_N, X_1, ..., X_T|A, B, pi)\n",
    "        vit = [[0 for x in range(self.M)] for y in range(len(obs))] \n",
    "        # matrix\n",
    "        path = {} \n",
    "        # path\n",
    "        # Initialize base cases (t == 0)\n",
    "        for y in range(self.M):\n",
    "            vit[0][y] = self.pi[0][y] * self.B[y][obs[0]]\n",
    "            path[y] = [y]\n",
    "        \n",
    "        # Run Viterbi for t > 0\n",
    "        for t in range(1, len(obs)):\n",
    "            newpath = {}\n",
    "            for y in range(self.M):\n",
    "                (prob, state) = max((vit[t-1][y0] * self.A[y0][y] * self.B[y][obs[t]], y0) \n",
    "                                    for y0 in range(self.M))\n",
    "                vit[t][y] = prob\n",
    "                newpath[y] = path[state] + [y]\n",
    "            # Don't need to remember the old paths\n",
    "            path = newpath\n",
    "        n = 0           \n",
    "        # if only one element is observed max is sought in the initialization values\n",
    "        if len(obs)!=1:\n",
    "            n = t\n",
    "        (prob, state) = max((vit[n][y], y) for y in range(self.M))\n",
    "        return (prob, path[state])\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward_backward(self, obs): \n",
    "        #Output matrix gamma: gamma[t][y]=P(q_t=j|Y_1, ..., Y_N,A,B,pi)\n",
    "        #and tensor zi: zi[t][i][j]=P(q_t=i,q_{t+1}=j|Y_1, ..., Y_N,A,B,pi)\n",
    "        gamma = [[0 for x in range(self.M)] for y in range(len(obs))]\n",
    "        # this is needed to keep track of finding a state i at a time t for all i and all t\n",
    "        zi = [[[0 for x in range(self.M)] for y in range(self.M)] for z in range(len(obs))]  \n",
    "        # this is needed to keep track of finding a state i at a time t and j at a time (t+1) \n",
    "        #for all i and all j and all t\n",
    "        # get alpha and beta tables computes\n",
    "        p_obs = self.forward(obs)\n",
    "        self.backward(obs)\n",
    "        # compute gamma values\n",
    "        for t in range(len(obs)):\n",
    "            for y in range(self.M):\n",
    "                gamma[t][y] = (self.fwd[t][y] * self.bwk[t][y]) / p_obs\n",
    "                if t == 0:\n",
    "                    self.pi[0][y] = gamma[t][y]\n",
    "                #gamma[t][y]=P(q_t=j|Y_1, ..., Y_N,A,B,pi)\n",
    "                #=P(q_t=j,Y_1, ..., Y_N|A,B,pi)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "                #=alpha_t(j)beta_t(j)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "                #compute zi values up to T - 1\n",
    "                if t == len(obs) - 1:\n",
    "                    continue\n",
    "                for y1 in range(self.M):\n",
    "                    zi[t][y][y1] = self.fwd[t][y] * self.A[y][y1] * self.B[y1][obs[t + 1]] * self.bwk[t + 1][y1] / p_obs\n",
    "        #zi[t][i][j]=P(q_t=i,q_{t+1}=j|Y_1, ..., Y_N,A,B,pi)\n",
    "        #=P(q_t=i,q_{t+1}=j,Y_1, ..., Y_N|A,B,pi)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "        #=alpha_t(i)a_{ij}b_j(O_{t+1})beta_{t+1}(j)/apha_t(X_T)\n",
    "        return (gamma,zi)\n",
    "    \n",
    "    \n",
    "    def baum_welch(self,obs):\n",
    "        # returns model given the initial model and observations  \n",
    "        #The Baum-Welch algorithm iteratively estimate the counts.\n",
    "        #We will start with an estimate for the transition and observation probabilities and \n",
    "        #then use these estimated probabilities to derive better and better probabilities. \n",
    "        #We get our estimated probabilities by computing the forward probability for \n",
    "        #an observation and then dividing that probability mass among all the different \n",
    "        #paths that contributed to this forward probability.\n",
    "        gamma = [[0 for x in range(self.M)] for y in range(len(obs))]\n",
    "        zi = [[[0 for x in range(self.M)] for y in range(self.M)] for z in range(len(obs))]  \n",
    "\n",
    "        # now that we have gamma and zi let us re-estimate\n",
    "        (gamma,zi)=self.forward_backward(obs)\n",
    "        for y in range(self.M):\n",
    "            for y1 in range(self.M):\n",
    "                # we will now compute new a_ij\n",
    "                #a_{ij)=expected number of transitions from state i to state j/expected number \n",
    "                #of transitions from state i\n",
    "                val = sum([zi[t][y][y1] for t in range(len(obs) - 1)]) #\n",
    "                val /= sum([gamma[t][y] for t in range(len(obs) - 1)])\n",
    "                self.A[y][y1] = val\n",
    "        # re estimate gamma\n",
    "        for y in range(self.M):\n",
    "            for k in range(self.N): \n",
    "                # for all symbols vk\n",
    "                val = 0.0\n",
    "                for t in range(len(obs)):\n",
    "                    if obs[t] == k :\n",
    "                        val += gamma[t][y]\n",
    "                val /= sum([gamma[t][y] for t in range(len(obs))])\n",
    "                self.B[y][k] = val\n",
    "                    #b_j(v_k)=expected number of times in state j and observing symbol vk/expected \n",
    "                    #number of times in state j\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M= 5 N= 2 Observations =  [0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "M=randint(0,10)\n",
    "N=randint(0,10)\n",
    "hmm=HMM(M,N)\n",
    "T=randint(0,10)\n",
    "observations = []\n",
    "for i in xrange(0,T):\n",
    "    observations.append(randint(0,N-1))\n",
    "#observations=[1,0,1,1]\n",
    "print \"M=\", M, \"N=\", N, \"Observations = \", observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fwd Prob =  0.103988308511\n"
     ]
    }
   ],
   "source": [
    "p1=hmm.backward(observations)\n",
    "print \" Fwd Prob = \", p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fwd Prob =  0.103988308511\n"
     ]
    }
   ],
   "source": [
    "p2=hmm.forward(observations)\n",
    "print \" Fwd Prob = \", p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Probability =  0.00537607558932  Hidden State Sequence =  [4, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "prob, hidden_states = hmm.viterbi(observations)\n",
    "print \"Max Probability = \", prob, \" Hidden State Sequence = \", hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zi=  [[[0.0011624564957250247, 0.0020030545878707193, 0.015631611790854025, 0.0091444324785135821, 0.0043859720749167518], [0.015426267521049362, 0.032237269649808588, 0.0070780183064178678, 0.032613453218488672, 0.010794374784312272], [0.044725449672599456, 0.019152057548830908, 0.045605457751467848, 0.01366066705866585, 0.019639764148948406], [0.052406826763653894, 0.015469885862274579, 0.091177137670446703, 0.086442060891582531, 0.13085897811145911], [0.10621852622921586, 0.12981980523480724, 0.00059821685199990568, 0.061711583659758838, 0.052036671636331966]], [[0.0076353920449904397, 0.012629478820593809, 0.10704930873531725, 0.063637799323571401, 0.028987547757770706], [0.030906681961741615, 0.061999443015460322, 0.014785250261079108, 0.069229639978866081, 0.021761057666444907], [0.049416064375145827, 0.020312664148362337, 0.052535846147762987, 0.015991496521152962, 0.021834371178762229], [0.027669036381096551, 0.0078402749170779235, 0.050190046557806053, 0.048354293889129651, 0.069518545561899292], [0.066223380494156603, 0.077694457699046607, 0.0003888617192538416, 0.040764444575684511, 0.032644616267826908]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]]\n",
      "gamma= [[0.032327527427880108, 0.098149383480076777, 0.14278339618051247, 0.37635488929941685, 0.35038480361211383], [0.21993952668224362, 0.19868207288359202, 0.16009044237118633, 0.20357219730700946, 0.21771576075596852], [0.18185055525713104, 0.18047631860054103, 0.22494931342121924, 0.23797767428840461, 0.17474613843270403]]\n"
     ]
    }
   ],
   "source": [
    "(gamma,zi)=hmm.forward_backward(observations)\n",
    "print \"zi= \", zi\n",
    "print \"gamma=\", gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new model parameters after 1 iteration are: \n",
      "A =  [[ 0.03487266  0.0579951   0.48632003  0.28852553  0.13228668]\n",
      " [ 0.15606466  0.31719979  0.0736942   0.34337246  0.10966889]\n",
      " [ 0.31102085  0.13060807  0.32366246  0.09772406  0.13698457]\n",
      " [ 0.13786515  0.04002849  0.24404239  0.23294095  0.34512302]\n",
      " [ 0.30346999  0.36622441  0.00173204  0.17961233  0.14896123]]\n",
      "B =  [[ 0.07648448  0.92351552]\n",
      " [ 0.20333554  0.79666446]\n",
      " [ 0.28740867  0.71259133]\n",
      " [ 0.38659414  0.61340586]\n",
      " [ 0.53887609  0.46112391]]\n",
      "pi =  [[ 0.03383755  0.10446205  0.14767661  0.28044915  0.43357465]]\n"
     ]
    }
   ],
   "source": [
    "hmm.baum_welch(observations)\n",
    "print \"The new model parameters after 1 iteration are: \"\n",
    "print \"A = \", hmm.A\n",
    "print \"B = \", hmm.B\n",
    "print \"pi = \", hmm.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
