{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "class HMM(object): \n",
    "    # base class for different HMM models\n",
    "    def __init__(self, M, N):\n",
    "        # model is (A, B, pi) where A = Transition probs(states*states), \n",
    "        #B = Emission Probs(states*obs), pi = initial distribution(states)        \n",
    "        # a model can be initialized to random parameters using a json file \n",
    "        #that has a random params model\n",
    "        # M:number of states of the model\n",
    "        # N:number of hidden states of the model\n",
    "        self.A_raw = np.random.random((M, M)) \n",
    "        self.row_sums_A = self.A_raw.sum(axis=1)\n",
    "        self.A = self.A_raw / self.row_sums_A[:, np.newaxis]\n",
    "        # Get transition probability\n",
    "        self.B_raw = np.random.random((M, N))\n",
    "        self.row_sums_B = self.B_raw.sum(axis=1)\n",
    "        self.B = self.B_raw / self.row_sums_B[:, np.newaxis]\n",
    "        # Get emission probability\n",
    "        self.pi_raw = np.random.random((1, M)) \n",
    "        self.row_sums_pi = self.pi_raw.sum(axis=1)\n",
    "        self.pi = self.pi_raw / self.row_sums_pi[:, np.newaxis]\n",
    "        # Get initial probability\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "    \n",
    "    def backward(self, obs):\n",
    "        # This function is for backward algorithm, suppose that A, B, pi \n",
    "        #are given, and it calculates a bwk matrix (obs*states).\n",
    "        # The backward algorithm can be used to calculate the likelihood \n",
    "        #of the probability P(Y_{k+1}, ... , Y_n|t_k=C)\n",
    "        #=sum_q P(Y_{k+2}, ... , Y_n|t_{k+1}=q)P(q|C)P(x_{k+1}|q)\n",
    "        #The backward probability b is the probability of seeing the observations from \n",
    "        #time t + 1 to the end, given that we are in state i at time t\n",
    "        self.bwk = [[0 for x in range(self.M)] for y in range(len(obs))] \n",
    "        #Initalize bwk to be empty matrix T*M\n",
    "        # Initialize base cases (t == T)\n",
    "        for y in range(self.M):\n",
    "            self.bwk[len(obs)-1][y] = 1 \n",
    "            #self.A[y][\"Final\"] #self.pi[y] * self.B[y][obs[0]]\n",
    "        for t in reversed(range(len(obs)-1)):\n",
    "            for y in range(self.M):\n",
    "                self.bwk[t][y] = sum((self.bwk[t+1][y1] * self.A[y][y1] * self.B[y1][obs[t+1]]) \n",
    "                                    for y1 in range(self.M))\n",
    "                #beta_k(C)=\\sum_q beta_{k+1}(q)P(q|C)P(w_{k+1}|q)\n",
    "        prob = sum((self.pi[0][y]* self.B[y][obs[0]] * self.bwk[0][y]) for y in range(self.M))\n",
    "\n",
    "        return prob \n",
    "        #This prob is the likelihood of the input obs   \n",
    "    \n",
    "    def forward(self, obs):\n",
    "        # This function is for forward algorithm, suppose that A, B, pi are given, \n",
    "        #and it calculates a fwd matrix (obs*states).\n",
    "        # The forward algorithm can be used to calculate the likelihood of the model\n",
    "        #P(Y1, ... , Yn)=sum_t(\\prod_i P(Y[i]|t[i])P(t[i]|t[i-1])\n",
    "        self.fwd = [[0 for x in range(self.M)] for y in range(len(obs))]  \n",
    "        #Initalize fwk to be empty matrix, and finally fwd is N*T\n",
    "        # Initialize base cases (t == 0)\n",
    "        for y in range(self.M):\n",
    "            self.fwd[0][y] = self.pi[0][y] * self.B[y][obs[0]] \n",
    "            #alpha_1(q)=p(w1,t1=q)=P(t1=q|t0)*p(w1|t1=q)\n",
    "        # Run Forward algorithm for t > 0\n",
    "        for t in range(1, len(obs)):\n",
    "            #self.fwd.append({})\n",
    "            for y in range(self.M):\n",
    "                self.fwd[t][y] = sum((self.fwd[t-1][y0] * self.A[y0][y] * self.B[y][obs[t]]) \n",
    "                                     for y0 in range(self.M))\n",
    "                #alpha_k(q)=\\sum_q1 alpha_{k-1}(q1)P(t_k=q|t_{k-1}=q1)P(w_k|t+k=q)\n",
    "        prob = sum((self.fwd[len(obs) - 1][s]) for s in range(self.M))\n",
    "        # The likelihood of input equals to the summation of fwd[N][t]\n",
    "        return prob\n",
    "\n",
    "    def viterbi(self, obs):\n",
    "    #the task of determining which sequence of variables is the underlying source \n",
    "    #of some sequence of observations is called the decoding task\n",
    "    #Decoding: Given as input an HMM = (A, B, pi) and a sequence of observations \n",
    "    #O = Y_1, ... Y_N, find the most probable sequence of states Q = X_1, ... X_T.\n",
    "    # Goal: find the best path!\n",
    "    # argmax_t P(Y1, ... Y_N, X_1, ..., X_T|A, B, pi)\n",
    "        vit = [[0 for x in range(self.M)] for y in range(len(obs))] \n",
    "        # matrix\n",
    "        path = {} \n",
    "        # path\n",
    "        # Initialize base cases (t == 0)\n",
    "        for y in range(self.M):\n",
    "            vit[0][y] = self.pi[0][y] * self.B[y][obs[0]]\n",
    "            path[y] = [y]\n",
    "        \n",
    "        # Run Viterbi for t > 0\n",
    "        for t in range(1, len(obs)):\n",
    "            #vit.append({})\n",
    "            newpath = {}\n",
    "            for y in range(self.M):\n",
    "                (prob, state) = max((vit[t-1][y0] * self.A[y0][y] * self.B[y][obs[t]], y0) \n",
    "                                    for y0 in range(self.M))\n",
    "                vit[t][y] = prob\n",
    "                newpath[y] = path[state] + [y]\n",
    "            # Don't need to remember the old paths\n",
    "            path = newpath\n",
    "        n = 0           \n",
    "        # if only one element is observed max is sought in the initialization values\n",
    "        if len(obs)!=1:\n",
    "            n = t\n",
    "        (prob, state) = max((vit[n][y], y) for y in range(self.M))\n",
    "        return (prob, path[state])\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward_backward(self, obs): \n",
    "        # returns model given the initial model and observations\n",
    "        #forward-backward algorithm is a special case of EM algorithm\n",
    "        #The Baum-Welch algorithm iteratively estimate the counts. \n",
    "        #We will start with an estimate for the transition and observation probabilities and \n",
    "        #then use these estimated probabilities to derive better and better probabilities. \n",
    "        #We get our estimated probabilities by computing the forward probability for \n",
    "        #an observation and then dividing that probability mass among all the different \n",
    "        #paths that contributed to this forward probability.\n",
    "        gamma = [[0 for x in range(self.M)] for y in range(len(obs))]\n",
    "        # this is needed to keep track of finding a state i at a time t for all i and all t\n",
    "        zi = [[[0 for x in range(self.M)] for y in range(self.M)] for z in range(len(obs))]  \n",
    "        # this is needed to keep track of finding a state i at a time t and j at a time (t+1) \n",
    "        #for all i and all j and all t\n",
    "        # get alpha and beta tables computes\n",
    "        p_obs = self.forward(obs)\n",
    "        self.backward(obs)\n",
    "        # compute gamma values\n",
    "        for t in range(len(obs)):\n",
    "            for y in range(self.M):\n",
    "                gamma[t][y] = (self.fwd[t][y] * self.bwk[t][y]) / p_obs\n",
    "                if t == 0:\n",
    "                    self.pi[0][y] = gamma[t][y]\n",
    "                #gamma[t][y]=P(q_t=j|Y_1, ..., Y_N,A,B,pi)\n",
    "                #=P(q_t=j,Y_1, ..., Y_N|A,B,pi)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "                #=alpha_t(j)beta_t(j)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "                #compute zi values up to T - 1\n",
    "                if t == len(obs) - 1:\n",
    "                    continue\n",
    "                #zi[t][y] = {}\n",
    "                for y1 in range(self.M):\n",
    "                    zi[t][y][y1] = self.fwd[t][y] * self.A[y][y1] * self.B[y1][obs[t + 1]] * self.bwk[t + 1][y1] / p_obs\n",
    "        #z[t][i][j]=P(q_t=i,q_{t+1}=j|Y_1, ..., Y_N,A,B,pi)\n",
    "        #=P(q_t=i,q_{t+1}=j,Y_1, ..., Y_N|A,B,pi)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "        #=alpha_t(i)a_{ij}b_j(O_{t+1})beta_{t+1}(j)/apha_t(X_T)\n",
    "        return (gamma,zi)\n",
    "    \n",
    "    \n",
    "    def baum_welch(self,obs):\n",
    "        gamma = [[0 for x in range(self.M)] for y in range(len(obs))]\n",
    "        # this is needed to keep track of finding a state i at a time t for all i and all t\n",
    "        zi = [[[0 for x in range(self.M)] for y in range(self.M)] for z in range(len(obs))]  \n",
    "        # this is needed to keep track of finding a state i at a time t and j at a time (t+1) \n",
    "        #for all i and all j and all t\n",
    "\n",
    "\n",
    "        # now that we have gamma and zi let us re-estimate\n",
    "        (gamma,zi)=self.forward_backward(obs)\n",
    "        for y in range(self.M):\n",
    "            for y1 in range(self.M):\n",
    "                # we will now compute new a_ij\n",
    "                #a_{ij)=expected number of transitions from state i to state j/expected number \n",
    "                #of transitions from state i\n",
    "                val = sum([zi[t][y][y1] for t in range(len(obs) - 1)]) #\n",
    "                val /= sum([gamma[t][y] for t in range(len(obs) - 1)])\n",
    "                self.A[y][y1] = val\n",
    "        # re estimate gamma\n",
    "        for y in range(self.M):\n",
    "            for k in range(self.N): \n",
    "                # for all symbols vk\n",
    "                val = 0.0\n",
    "                for t in range(len(obs)):\n",
    "                    if obs[t] == k :\n",
    "                        val += gamma[t][y]\n",
    "                val /= sum([gamma[t][y] for t in range(len(obs))])\n",
    "                self.B[y][k] = val\n",
    "                    #b_j(v_k)=expected number of times in state j and observing symbol vk/expected \n",
    "                    #number of times in state j\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M= 4 N= 7 Observations =  [4, 5, 2, 6, 5, 2, 6, 1]\n"
     ]
    }
   ],
   "source": [
    "M=randint(0,10)\n",
    "N=randint(0,10)\n",
    "hmm=HMM(M,N)\n",
    "T=randint(0,10)\n",
    "observations = []\n",
    "for i in xrange(0,T):\n",
    "    observations.append(randint(0,N-1))\n",
    "#observations=[1,0,1,1]\n",
    "print \"M=\", M, \"N=\", N, \"Observations = \", observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fwd Prob =  4.91785348585e-07\n"
     ]
    }
   ],
   "source": [
    "p1=hmm.backward(observations)\n",
    "print \" Fwd Prob = \", p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fwd Prob =  4.91785348585e-07\n"
     ]
    }
   ],
   "source": [
    "p2=hmm.forward(observations)\n",
    "print \" Fwd Prob = \", p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Probability =  6.46454266625e-09  Hidden State Sequence =  [3, 1, 3, 0, 1, 3, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "prob, hidden_states = hmm.viterbi(observations)\n",
    "print \"Max Probability = \", prob, \" Hidden State Sequence = \", hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zi=  [[[0.0084594922431747693, 0.046923410368640291, 0.013112457626554604, 0.0024389435020313252], [0.00015655667542833525, 1.1354798197827114e-05, 0.00012819504328365666, 8.7777029051073636e-05], [0.00030255031108179575, 0.00057546464574836139, 0.00063128722745130932, 0.0001722311156064356], [0.21072661792093059, 0.47911996096633963, 0.22260446465710201, 0.014549235869378136]], [[0.057195533926299905, 0.095633752808221589, 0.033976997626168196, 0.03283893278992582], [0.21475509108690968, 0.0046952109106159455, 0.067394769356110745, 0.23978511942528979], [0.067435760343828602, 0.038664741396807818, 0.053926562490019196, 0.076449340323735987], [0.0077425123406283268, 0.0053065294836810856, 0.0031345807332265824, 0.0010645649585309736]], [[0.12073475735359324, 0.16784493495925504, 0.043960331024113411, 0.014588874360704822], [0.099826405560136416, 0.0018146125821096554, 0.019201445149719883, 0.023457771307360476], [0.07183759785498782, 0.034245499056576013, 0.035210325477599516, 0.017139487816361352], [0.18957896536008603, 0.10803032201500953, 0.047042832312083359, 0.0054858378103037038]], [[0.056318425743860701, 0.32079926049558505, 0.088437194033455735, 0.016422845855902039], [0.12623231469684612, 0.0094019070937968203, 0.10471643193282665, 0.07158471488948065], [0.025769629902912341, 0.050334621196285748, 0.054473117033921423, 0.014837565830396658], [0.013558323729844685, 0.031656904536096583, 0.014509923398489711, 0.0009468196302993791]], [[0.060520501157525518, 0.093402251774775805, 0.034169113290979769, 0.033786827850182714], [0.1714537434471968, 0.0034599064800054291, 0.051137325045836762, 0.18614171834872514], [0.07729156786989945, 0.040903711749460545, 0.058742565212135736, 0.085198821567197769], [0.048251206483734668, 0.030524081412610725, 0.018565816017780151, 0.0064508422919531717]], [[0.11596018455341037, 0.18851370587114141, 0.039303660100970673, 0.013739468432833975], [0.11762549493276916, 0.002500334161199453, 0.021061311096835914, 0.027102811226047959], [0.072348385643645319, 0.040330968327092008, 0.033009773155101653, 0.016925692440893429], [0.16179707973904175, 0.10781627109337946, 0.037373988583683383, 0.0045908706419541569]], [[0.080366635095206293, 0.33349812320038386, 0.022273327941888552, 0.031593058631387852], [0.17258777981481474, 0.0093646210685392403, 0.025268485357129233, 0.13194039321232909], [0.036601354739780101, 0.052082346298651438, 0.013655137710377262, 0.028409894187782826], [0.020897788802937099, 0.035546556880379679, 0.0039471563957805622, 0.0019673406626321763]], [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]]\n",
      "gamma= [[0.070934303740400995, 0.00038388354596089272, 0.0016815332998879023, 0.92700027941375052], [0.2196452171506155, 0.52663019077892614, 0.23647640455439159, 0.017248187516066969], [0.34712889769766653, 0.14430023459932642, 0.15843291020552472, 0.35013795749748255], [0.48197772612880346, 0.31193536861295024, 0.14541493396351615, 0.060671971294730363], [0.22187869407346383, 0.41219269332176423, 0.26213666639869349, 0.10379194620607872], [0.35751701895835641, 0.16828995141685252, 0.1626148195667324, 0.3115782100580588], [0.46773114486886663, 0.33916127945281233, 0.13074873293659162, 0.062358842741729516], [0.31045355845273825, 0.43049164744795421, 0.065144107405175608, 0.19391068669413192]]\n"
     ]
    }
   ],
   "source": [
    "(gamma,zi)=hmm.forward_backward(observations)\n",
    "print \"zi= \", zi\n",
    "print \"gamma=\", gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new model parameters after 1 iteration are: \n",
      "A =  [[ 0.23396321  0.57230734  0.12534276  0.06838669]\n",
      " [ 0.47504189  0.01643728  0.15174274  0.35677809]\n",
      " [ 0.32035989  0.23401991  0.22740174  0.21821847]\n",
      " [ 0.35125796  0.4384997   0.19126879  0.01897355]]\n",
      "B =  [[  0.00000000e+00   1.28400596e-01   2.90807586e-01   0.00000000e+00\n",
      "    2.38371856e-03   1.85366568e-01   3.93041532e-01]\n",
      " [  0.00000000e+00   1.85034690e-01   1.35622846e-01   0.00000000e+00\n",
      "    1.93178285e-07   3.99946278e-01   2.79395993e-01]\n",
      " [  0.00000000e+00   5.58758389e-02   2.75730401e-01   0.00000000e+00\n",
      "    9.61418837e-04   4.30527309e-01   2.36905033e-01]\n",
      " [  0.00000000e+00   9.28020243e-02   3.15747080e-01   0.00000000e+00\n",
      "    4.75218071e-01   5.71564105e-02   5.90764140e-02]]\n",
      "pi =  [[  5.76389497e-03   4.49384068e-07   1.12091722e-03   9.93114738e-01]]\n"
     ]
    }
   ],
   "source": [
    "hmm.baum_welch(observations)\n",
    "print \"The new model parameters after 1 iteration are: \"\n",
    "print \"A = \", hmm.A\n",
    "print \"B = \", hmm.B\n",
    "print \"pi = \", hmm.pi"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
