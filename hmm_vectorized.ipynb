{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "class HMM(object): \n",
    "    # base class for different HMM models\n",
    "    def __init__(self, T, O, pi):\n",
    "        # model is (T, O, pi) where T = Transition probs(hidden_states*hidden_states), \n",
    "        # O = Emission Probs(hidden_states*states), pi = initial distribution(hidden_states)               \n",
    "        if T is None:\n",
    "            print \"Error: You should provide the transition matrix\"\n",
    "            sys.exit() # Read in parameters from the file of model_name\n",
    "        if O is None:\n",
    "            print \"Error: You should provide the emission matrix\"\n",
    "            sys.exit() # Read in parameters from the file of model_name\n",
    "        if pi is None:\n",
    "            print \"Error: You should provide the initial probability\"\n",
    "            sys.exit() # Read in parameters from the file of model_name           \n",
    "        self.pi=pi\n",
    "        self.T=T\n",
    "        self.O=O\n",
    "        self.M=T.shape[1]  # M:number of hidden states of the model\n",
    "        self.N=O.shape[1]  # N:number of states of the model\n",
    "\n",
    "        \n",
    "    def backward(self, obs):\n",
    "        # This function is for backward algorithm, suppose that T, O, pi \n",
    "        #are given, and it calculates a bwk matrix (obs*states).\n",
    "        # The backward algorithm can be used to calculate the likelihood \n",
    "        #of the probability P(Y_{k+1}, ... , Y_n|t_k=C)\n",
    "        #=sum_q P(Y_{k+2}, ... , Y_n|t_{k+1}=q)P(q|C)P(x_{k+1}|q)\n",
    "        #The backward probability b is the probability of seeing the observations from \n",
    "        #time t + 1 to the end, given that we are in state i at time t\n",
    "        self.bwk = np.zeros(shape=(len(obs),self.M))\n",
    "        # Initalize bwk to be empty matrix T*M\n",
    "        # Initialize base cases (t == T)\n",
    "        self.bwk[len(obs)-1,:]=np.ones(self.M)      \n",
    "        for t in reversed(range(len(obs)-1)):\n",
    "            self.bwk[t,:] = np.sum(self.bwk[t+1,:] * self.T[:,:] * self.O[:,obs[t+1]],axis=1)        \n",
    "                #beta_k(C)=\\sum_q beta_{k+1}(q)P(q|C)P(w_{k+1}|q)\n",
    "        prob = np.sum(self.pi[0,:]* self.O[:,obs[0]] * self.bwk[0,:]) \n",
    "        return prob \n",
    "        #This prob is the likelihood of the input obs   \n",
    " \n",
    "\n",
    "    def forward(self, obs):\n",
    "        # This function is for forward algorithm, suppose that A, B, pi are given, \n",
    "        #and it calculates a fwd matrix (obs*states).\n",
    "        # The forward algorithm can be used to calculate the likelihood of the model\n",
    "        #P(Y1, ... , Yn)=sum_t(\\prod_i P(Y[i]|t[i])P(t[i]|t[i-1])\n",
    "        self.fwd = np.zeros(shape=(len(obs),self.M)) \n",
    "        #Initalize fwk to be empty matrix, and finally fwd is T*M\n",
    "        # Initialize base cases (t == 0)\n",
    "        self.fwd[0,:]=self.pi[0,:] * self.O[:,obs[0]] \n",
    "            #alpha_1(q)=p(w1,t1=q)=P(t1=q|t0)*p(w1|t1=q)\n",
    "        # Run Forward algorithm for t > 0            \n",
    "        for t in range(1, len(obs)):\n",
    "            self.fwd[t,:] = np.sum(self.fwd[t-1,:] * self.T[:,:] * self.O[:,obs[t]],axis=1) \n",
    "                #alpha_k(q)=\\sum_q1 alpha_{k-1}(q1)P(t_k=q|t_{k-1}=q1)P(w_k|t+k=q)\n",
    "        prob = np.sum(self.fwd[len(obs) - 1,:]) \n",
    "        # The likelihood of input equals to the summation of fwd[N][t]\n",
    "        return prob\n",
    "\n",
    "    def viterbi(self, obs):\n",
    "    #the task of determining which sequence of variables is the underlying source \n",
    "    #of some sequence of observations is called the decoding task\n",
    "    #Decoding: Given as input an HMM = (A, B, pi) and a sequence of observations \n",
    "    #O = Y_1, ... Y_N, find the most probable sequence of states Q = X_1, ... X_T.\n",
    "    # Goal: find the best path!\n",
    "    # argmax_t P(Y1, ... Y_N, X_1, ..., X_T|A, B, pi)\n",
    "        vit = np.zeros(shape=(len(obs),self.M))\n",
    "        #[[0 for x in range(self.M)] for y in range(len(obs))] \n",
    "        # matrix\n",
    "        path = {} \n",
    "        # path\n",
    "        # Initialize base cases (t == 0)\n",
    "        vit[0,:] = self.pi[0,:] * self.O[:,obs[0]]\n",
    "        for y in range(self.M):\n",
    "            path[y] = [y]           \n",
    "        #for y in range(self.M):\n",
    "            #vit[0][y] = self.pi[0][y] * self.O[y][obs[0]]\n",
    "            #path[y] = [y]\n",
    "        \n",
    "        # Run Viterbi for t > 0\n",
    "        \n",
    "        for t in range(1, len(obs)):\n",
    "            newpath = {}\n",
    "            for y in range(self.M):\n",
    "                (prob, state) = max((vit[t-1][y0] * self.T[y0][y] * self.O[y][obs[t]], y0) \n",
    "                                    for y0 in range(self.M))\n",
    "                vit[t][y] = prob\n",
    "                newpath[y] = path[state] + [y]\n",
    "            # Don't need to remember the old paths\n",
    "            path = newpath\n",
    "        n = 0                      \n",
    "        # if only one element is observed max is sought in the initialization values\n",
    "        if len(obs)!=1:\n",
    "            n = t\n",
    "        (prob, state) = max((vit[n][y], y) for y in range(self.M))\n",
    "        return (prob, path[state])\n",
    "    \n",
    "    def viterbi(self, obs):\n",
    "    #the task of determining which sequence of variables is the underlying source \n",
    "    #of some sequence of observations is called the decoding task\n",
    "    #Decoding: Given as input an HMM = (A, B, pi) and a sequence of observations \n",
    "    #O = Y_1, ... Y_N, find the most probable sequence of states Q = X_1, ... X_T.\n",
    "    # Goal: find the best path!\n",
    "    # argmax_t P(Y1, ... Y_N, X_1, ..., X_T|A, B, pi)\n",
    "        vit = np.zeros(shape=(len(obs),self.M))\n",
    "        #[[0 for x in range(self.M)] for y in range(len(obs))] \n",
    "        # matrix\n",
    "        path=np.zeros(shape=(len(obs),self.M))\n",
    "        path[0,:]=range(self.M)\n",
    "        # path\n",
    "        # Initialize base cases (t == 0)\n",
    "        vit[0,:] = self.pi[0,:] * self.O[:,obs[0]]    \n",
    "        # Run Viterbi for t > 0      \n",
    "        for t in range(1, len(obs)):\n",
    "            vit[t,:]=np.max(vit[t-1,:] * self.T[:,:] * self.O[:,obs[t]],axis=1)\n",
    "            path[t,:]=np.argmax(vit[t-1,:] * self.T[:,:] * self.O[:,obs[t]],axis=1)\n",
    "        prob=np.max(vit[len(obs)-1,:])\n",
    "        ind=np.argmax(vit[len(obs)-1,:])\n",
    "        state=path[:,ind]\n",
    "        #(prob, state) = max((vit[n][y], y) for y in range(self.M))\n",
    "        return (prob, state)\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward_backward(self, obs): \n",
    "        #Output matrix gamma: gamma[t][y]=P(q_t=j|Y_1, ..., Y_N,A,B,pi)\n",
    "        #and tensor zi: zi[t][i][j]=P(q_t=i,q_{t+1}=j|Y_1, ..., Y_N,A,B,pi)\n",
    "        gamma = np.zeros(shape=(len(obs),self.M))\n",
    "        # this is needed to keep track of finding a state i at a time t for all i and all t\n",
    "        zi= np.zeros(shape=(len(obs),self.M,self.M))\n",
    "        #zi = [[[0 for x in range(self.M)] for y in range(self.M)] for z in range(len(obs))]  \n",
    "        # this is needed to keep track of finding a state i at a time t and j at a time (t+1) \n",
    "        #for all i and all j and all t\n",
    "        # get alpha and beta tables computes\n",
    "        p_obs = self.forward(obs)\n",
    "        self.backward(obs)\n",
    "        # compute gamma values\n",
    "        for t in range(len(obs)):\n",
    "            gamma[t,:] = (self.fwd[t,:] * self.bwk[t,:]) / p_obs\n",
    "            if t == 0:\n",
    "                self.pi[0,:] = gamma[t,:]\n",
    "                #gamma[t][y]=P(q_t=j|Y_1, ..., Y_N,A,B,pi)\n",
    "                #=P(q_t=j,Y_1, ..., Y_N|A,B,pi)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "                #=alpha_t(j)beta_t(j)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "                #compute zi values up to T - 1\n",
    "            if t == len(obs) - 1:\n",
    "                continue\n",
    "            for y1 in range(self.M):\n",
    "                zi[t,:,:] = self.fwd[t,:] * self.T[:,:] * self.O[:,obs[t + 1]] * self.bwk[t + 1,:] / p_obs\n",
    "        #zi[t][i][j]=P(q_t=i,q_{t+1}=j|Y_1, ..., Y_N,A,B,pi)       \n",
    "        #=P(q_t=i,q_{t+1}=j,Y_1, ..., Y_N|A,B,pi)/P(Y_1, ..., Y_N|A,B,pi)\n",
    "        #=alpha_t(i)a_{ij}b_j(O_{t+1})beta_{t+1}(j)/apha_t(X_T)\n",
    "        return (gamma,zi)\n",
    "    \n",
    "    \n",
    "    def baum_welch(self,obs):\n",
    "        #returns model given the initial model and observations  \n",
    "        #The Baum-Welch algorithm iteratively estimate the counts.\n",
    "        #We will start with an estimate for the transition and observation probabilities and \n",
    "        #then use these estimated probabilities to derive better and better probabilities. \n",
    "        #We get our estimated probabilities by computing the forward probability for \n",
    "        #an observation and then dividing that probability mass among all the different \n",
    "        #paths that contributed to this forward probability.\n",
    "        gamma = np.zeros(shape=(len(obs),self.M))\n",
    "        zi =  np.zeros(shape=(len(obs),self.M,self.M))\n",
    "        # now that we have gamma and zi let us re-estimate\n",
    "        (gamma,zi)=self.forward_backward(obs)\n",
    "        \n",
    "        #Update T\n",
    "        #T_{ij)=expected number of transitions from state i to state j/expected number \n",
    "        #of transitions from state i\n",
    "        a=np.sum(zi,axis=(0,2))\n",
    "        self.T=np.sum(zi,axis=0)/np.array([a,]*self.M).transpose()\n",
    "        \n",
    "        for y in range(self.M):\n",
    "            for k in range(self.N): \n",
    "                # for all symbols vk\n",
    "                val = 0.0\n",
    "                for t in range(len(obs)):\n",
    "                    if obs[t] == k :\n",
    "                        val += gamma[t][y]\n",
    "                val /= np.sum(gamma[:,y])\n",
    "                self.O[y][k] = val\n",
    "                #O_j(v_k)=expected number of times in state j and observing symbol vk/expected \n",
    "                #number of times in state j\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M=randint(1,10)\n",
    "N=randint(1,10)   \n",
    "T_raw = np.random.random((M, M)) \n",
    "row_sums_T= T_raw.sum(axis=1)\n",
    "T = T_raw / row_sums_T[:, np.newaxis]\n",
    "# Get transition probability\n",
    "O_raw = np.random.random((M, N))\n",
    "row_sums_O = O_raw.sum(axis=1)\n",
    "O = O_raw / row_sums_O[:, np.newaxis]\n",
    "# Get emission probability\n",
    "pi_raw = np.random.random((1, M)) \n",
    "row_sums_pi = pi_raw.sum(axis=1)\n",
    "pi = pi_raw / row_sums_pi[:, np.newaxis]\n",
    "# Get initial probability\n",
    "hmm=HMM(T,O,pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M= 5 N= 10 Observations =  [1, 2, 9, 5, 2, 9, 6, 5, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "#M=randint(0,10)\n",
    "#N=randint(0,10)\n",
    "#hmm=HMM(M,N)\n",
    "T=randint(3,10)\n",
    "observations = []\n",
    "for i in xrange(0,T):\n",
    "    observations.append(randint(0,N-1))\n",
    "#observations=[1,0,1,1]\n",
    "print \"M=\", M, \"N=\", N, \"Observations = \", observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bwk Prob =  1.26124358265e-10\n"
     ]
    }
   ],
   "source": [
    "p1=hmm.backward(observations)\n",
    "print \" Bwk Prob = \", p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fwd Prob =  8.73219878763e-11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p2=hmm.forward(observations)\n",
    "print \" Fwd Prob = \", p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Probability =  2.83094538061e-14  Hidden State Sequence =  [ 3.  3.  4.  2.  3.  3.  2.  2.  4.  2.]\n"
     ]
    }
   ],
   "source": [
    "prob, hidden_states = hmm.viterbi(observations)\n",
    "print \"Max Probability = \", prob, \" Hidden State Sequence = \", hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zi=  [[[ 0.0725164   0.00858647  0.0464077   0.06412959  0.0085393 ]\n",
      "  [ 0.08538378  0.02822664  0.00101909  0.0533444   0.01601303]\n",
      "  [ 0.03156583  0.0468396   0.03712087  0.01980767  0.01254935]\n",
      "  [ 0.02656295  0.00190302  0.04867907  0.08901764  0.01119171]\n",
      "  [ 0.07169858  0.05187529  0.048508    0.01609206  0.0043998 ]]\n",
      "\n",
      " [[ 0.03372423  0.00586407  0.00913866  0.04542717  0.07937953]\n",
      "  [ 0.0397083   0.01927719  0.00020068  0.03778731  0.14885372]\n",
      "  [ 0.0146799   0.03198878  0.00730989  0.01403106  0.11665613]\n",
      "  [ 0.01235328  0.00129965  0.00958594  0.063057    0.10403576]\n",
      "  [ 0.0333439   0.03542787  0.00955225  0.01139906  0.04089964]]\n",
      "\n",
      " [[ 0.03055526  0.01359399  0.08448225  0.02668307  0.018911  ]\n",
      "  [ 0.03597702  0.04468805  0.00185519  0.02219556  0.03546219]\n",
      "  [ 0.01330047  0.07415586  0.06757617  0.00824158  0.02779159]\n",
      "  [ 0.01119248  0.00301284  0.08861714  0.0370385   0.02478498]\n",
      "  [ 0.03021067  0.08212829  0.08830571  0.00669559  0.00974373]]\n",
      "\n",
      " [[ 0.06364758  0.01028348  0.04459157  0.06758529  0.00277248]\n",
      "  [ 0.07494127  0.0338053   0.00097921  0.05621892  0.00519899]\n",
      "  [ 0.0277053   0.05609691  0.03566818  0.02087503  0.00407443]\n",
      "  [ 0.02331428  0.00227913  0.04677406  0.09381447  0.00363364]\n",
      "  [ 0.06292979  0.06212784  0.04660968  0.01695921  0.0014285 ]]\n",
      "\n",
      " [[ 0.02913683  0.00500508  0.00801637  0.03042814  0.08730878]\n",
      "  [ 0.0343069   0.01645341  0.00017604  0.02531079  0.16372277]\n",
      "  [ 0.01268304  0.02730297  0.00641218  0.00939832  0.12830895]\n",
      "  [ 0.0106729   0.00110928  0.00840872  0.042237    0.11442793]\n",
      "  [ 0.02880823  0.03023829  0.00837917  0.00763535  0.04498512]]\n",
      "\n",
      " [[ 0.05525926  0.01762653  0.07377406  0.00722692  0.00216563]\n",
      "  [ 0.06506452  0.05794438  0.00162004  0.00601151  0.00406102]\n",
      "  [ 0.02405393  0.09615356  0.05901085  0.00223217  0.00318261]\n",
      "  [ 0.02024161  0.00390657  0.07738485  0.01003161  0.0028383 ]\n",
      "  [ 0.05463607  0.10649095  0.0771129   0.00181345  0.00111582]]\n",
      "\n",
      " [[ 0.02851159  0.00794473  0.11262693  0.02183653  0.02848158]\n",
      "  [ 0.03357072  0.02611703  0.00247323  0.0181641   0.05340909]\n",
      "  [ 0.01241088  0.04333889  0.09008872  0.00674464  0.04185651]\n",
      "  [ 0.01044387  0.00176079  0.11813934  0.03031107  0.03732829]\n",
      "  [ 0.02819005  0.04799822  0.11772415  0.00547945  0.01467489]]\n",
      "\n",
      " [[ 0.00667098  0.00488932  0.0767619   0.06671898  0.0570935 ]\n",
      "  [ 0.00785469  0.01607285  0.00168565  0.05549831  0.10706261]\n",
      "  [ 0.00290383  0.02667147  0.06140078  0.02060745  0.08390458]\n",
      "  [ 0.0024436   0.00108362  0.08051893  0.09261195  0.07482742]\n",
      "  [ 0.00659575  0.0295389   0.08023596  0.01674182  0.02941695]]\n",
      "\n",
      " [[ 0.00680945  0.00710852  0.0745375   0.06925298  0.04951773]\n",
      "  [ 0.00801773  0.0233681   0.00163681  0.05760615  0.09285641]\n",
      "  [ 0.0029641   0.0387773   0.0596215   0.02139013  0.07277123]\n",
      "  [ 0.00249432  0.00157546  0.07818565  0.09612937  0.06489852]\n",
      "  [ 0.00673266  0.04294621  0.07791088  0.01737768  0.02551359]]\n",
      "\n",
      " [[ 0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.        ]]]\n",
      "gamma= [[ 0.21416314  0.11883647  0.18694245  0.1523334   0.77208423]\n",
      " [ 0.19149804  0.24520804  0.14316256  0.18759449  0.13079327]\n",
      " [ 0.16720227  0.18813376  0.18363942  0.17397589  0.15268035]\n",
      " [ 0.19222208  0.1365289   0.17320272  0.163706    0.25815267]\n",
      " [ 0.17364717  0.23010797  0.139073    0.17222696  0.12281424]\n",
      " [ 0.14611709  0.16647633  0.16445101  0.11727433  0.16369574]\n",
      " [ 0.1670459   0.11268209  0.21454642  0.11750266  0.31387466]\n",
      " [ 0.20865037  0.13025373  0.20225634  0.24351052  0.18738702]\n",
      " [ 0.2120745   0.19129048  0.21210816  0.29325934  0.13961122]\n",
      " [ 0.20722618  0.1834852   0.19552427  0.24328333  0.17048103]]\n"
     ]
    }
   ],
   "source": [
    "(gamma,zi)=hmm.forward_backward(observations)\n",
    "print \"zi= \", zi\n",
    "print \"gamma=\", gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new model parameters after 1 iteration are: \n",
      "T =  [[ 0.20751546  0.04502675  0.3039349   0.2470225   0.19650038]\n",
      " [ 0.25112024  0.15212734  0.00685955  0.21118298  0.37870989]\n",
      " [ 0.09567416  0.26015516  0.25749683  0.08081177  0.30586207]\n",
      " [ 0.07561809  0.00992738  0.31715239  0.34110595  0.25619619]\n",
      " [ 0.21414219  0.28391871  0.33157462  0.06469448  0.10567001]]\n",
      "O =  [[ 0.          0.13958937  0.19558282  0.          0.          0.20469175\n",
      "   0.08538272  0.21431611  0.          0.16043723]\n",
      " [ 0.          0.02217813  0.31005716  0.          0.          0.16129387\n",
      "   0.06786475  0.22573829  0.          0.2128678 ]\n",
      " [ 0.          0.07024183  0.15333482  0.          0.          0.2168669\n",
      "   0.1239185   0.23543576  0.          0.20020219]\n",
      " [ 0.          0.09714309  0.19638149  0.          0.          0.21302628\n",
      "   0.06152159  0.28089757  0.          0.15102997]\n",
      " [ 0.          0.39997558  0.08868542  0.          0.          0.16323246\n",
      "   0.11526723  0.11387683  0.          0.11896249]]\n",
      "pi =  [[ 0.27310135  0.03682069  0.12161617  0.18555354  1.08915205]]\n"
     ]
    }
   ],
   "source": [
    "hmm.baum_welch(observations)\n",
    "print \"The new model parameters after 1 iteration are: \"\n",
    "print \"T = \", hmm.T\n",
    "print \"O = \", hmm.O\n",
    "print \"pi = \", hmm.pi"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
